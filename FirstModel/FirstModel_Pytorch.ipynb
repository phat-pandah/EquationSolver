{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good imports\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch as T\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "from torchvision import transforms\n",
    " \n",
    "device  = T.device(\"cpu\")\n",
    "T.manual_seed(42)\n",
    "\n",
    "print('Good imports')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240520/240520 [00:00<00:00, 705234.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "df = pd.read_csv('data.csv', index_col=False)\n",
    "\n",
    "# Extract labels\n",
    "labels_unordered = np.array(df[['784']])\n",
    "# Need labels used to be numbered correctly to call to_categorical()\n",
    "labels = np.copy(labels_unordered)\n",
    "labels = np.where(labels == 49, 10, labels)\n",
    "labels = np.where(labels == 50, 11, labels)\n",
    "labels = np.where(labels == 51, 12, labels)\n",
    "labels = np.where(labels == 52, 13, labels)\n",
    "labels = np.where(labels == 82, 14, labels)\n",
    "labels = np.where(labels == 33, 15, labels)\n",
    "labels = np.where(labels == 34, 16, labels)\n",
    "\n",
    "\n",
    "# Drop label col from data\n",
    "df.drop(columns=['784'], inplace=True)\n",
    "\n",
    "# Transomform data from 784x1 to 28x28 shape\n",
    "data2D = []\n",
    "tmp_data = df.values\n",
    "for img in tqdm(tmp_data):\n",
    "    data2D.append(img.reshape(1,28,28))\n",
    "data2D = np.array(data2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchDataSet(Dataset):\n",
    "    def __init__(self, data, labels, transforms=None):\n",
    "        self.X = data\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        data = self.X.iloc[i,:]\n",
    "        data = np.array(data).astype(np.uint8).reshape(1, 28, 28) \n",
    "        \n",
    "        # apply transforms if there are any\n",
    "        if self.transforms:\n",
    "            data = self.transforms(data)\n",
    "        \n",
    "        # return tuple of data + label if given a label set\n",
    "        if self.labels is not None:\n",
    "            return (data, self.y[i])\n",
    "        \n",
    "        else:\n",
    "            return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data & load into custum torch dataset\n",
    "data_train, data_val, label_train, label_val = train_test_split(data2D, labels, test_size=0.1, random_state=42)\n",
    "transformations = transforms.ToTensor()\n",
    "\n",
    "train_data = TorchDataSet(data_train, label_train, transformations)\n",
    "validation_data = TorchDataSet(data_val, label_val, transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input img shape = (num_imgs, 1, 28, 28)\n",
    "# after first Conv2d = (num_imgs, 16, 28, 28)\n",
    "# after first MaxPool2d layer = (num_imgs, 16, 14, 14)\n",
    "# after second Conv2d = (num_imgs, 32, 14, 14)\n",
    "# after second MaxPool2d layer = (num_imgs, 32, 7, 7)\n",
    "# after flatten = (num_imgs, 32*7*7)\n",
    "# i.e. input of first dense layer should be 32*7*7\n",
    "\n",
    "class basicModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(basicModel, self).__init__()\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 5, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, 5, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        self.lin_layers = nn.Sequential(\n",
    "            nn.Linear(32*7*7, 128),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Linear(64, num_classes),\n",
    "        )\n",
    "\n",
    "        # self.softmax = nn.LogSoftmax(num_classes)\n",
    "    @profile\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.lin_layers(x)\n",
    "        # x = self.softmax(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "num_classes = len(np.unique(labels))\n",
    "model = basicModel(num_classes)\n",
    "loss_funk = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do:\n",
    "--------------\n",
    "- ReWrite train function\n",
    "- call DataLoader on PytorchDataSet to load data into model\n",
    "- specify batchsize, number of epoches and learning rate for Adam opt\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = \n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    data_train, label_train = Variable(train_data), Variable(train_label)\n",
    "    data_val, label_val = Variable(val_data), Variable(val_label)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output_train = model(train_data)\n",
    "    output_val = model(val_data)\n",
    "    \n",
    "    loss_train = loss_funk(output_train, train_label)\n",
    "    loss_val = loss_funk(output_val, val_label)\n",
    "    train_losses.append(loss_train)\n",
    "    val_losses.append(loss_val)\n",
    "    \n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    tr_loss = loss_train.item()\n",
    "    \n",
    "\n",
    "    # computing the updated weights of all the model parameters\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    tr_loss = loss_train.item()\n",
    "    \n",
    "    print('\\n=====================================')\n",
    "    print(f'Epoch: {epoch+1}\\t loss: {loss_val}')\n",
    "    print('=====================================')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Variable data has to be a tensor, but got Subset",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-6f317238c24c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-45-68553a6a66ed>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtr_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mdata_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mdata_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Variable data has to be a tensor, but got Subset"
     ]
    }
   ],
   "source": [
    "for i in range(num_epoch):\n",
    "    train(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dba8851dec06c95965c4b9acd8f4325acdb80444c005ae414d7a6bcd36173821"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
