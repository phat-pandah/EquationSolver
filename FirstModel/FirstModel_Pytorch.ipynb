{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from tqdm import tqdm\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "from torch.autograd import Variable\r\n",
    "from torch import optim\r\n",
    "\r\n",
    "from memory_profiler import profile\r\n",
    "\r\n",
    "print('Good imports')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Good imports\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df = pd.read_csv('data.csv', index_col=False)\r\n",
    "\r\n",
    "\r\n",
    "labels_unordered = np.array(df[['784']])\r\n",
    "# Need labels used to be numbered correctly to call to_categorical()\r\n",
    "labels = np.copy(labels_unordered)\r\n",
    "labels = np.where(labels == 49, 10, labels)\r\n",
    "labels = np.where(labels == 50, 11, labels)\r\n",
    "labels = np.where(labels == 51, 12, labels)\r\n",
    "labels = np.where(labels == 52, 13, labels)\r\n",
    "labels = np.where(labels == 82, 14, labels)\r\n",
    "labels = np.where(labels == 33, 15, labels)\r\n",
    "labels = np.where(labels == 34, 16, labels)\r\n",
    "\r\n",
    "\r\n",
    "# Drop label col from data\r\n",
    "df.drop(columns=['784'], inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# transform data to 28x28\r\n",
    "data2D = []\r\n",
    "tmp_data = df.values\r\n",
    "for img in tqdm(tmp_data):\r\n",
    "    data2D.append(img.reshape(1,28,28))\r\n",
    "data2D = np.array(data2D)\r\n",
    "\r\n",
    "# split data into train & validation sets\r\n",
    "train_data, val_data, train_label, val_label = train_test_split(data2D, labels, test_size=0.1, random_state=42)\r\n",
    "\r\n",
    "train_data = torch.from_numpy(train_data)\r\n",
    "train_label = torch.from_numpy(train_label)\r\n",
    "val_data = torch.from_numpy(val_data)\r\n",
    "val_label = torch.from_numpy(val_label)\r\n",
    "\r\n",
    "print(f\"train data: {train_data.shape}, train label: {train_label.shape} val data: {val_data.shape} val label {val_label.shape}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 240520/240520 [00:00<00:00, 710389.87it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train data: torch.Size([216468, 1, 28, 28]), train label: torch.Size([216468, 1]) val data: torch.Size([24052, 1, 28, 28]) val label torch.Size([24052, 1])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# input img shape = (num_imgs, 1, 28, 28)\r\n",
    "# after first Conv2d = (num_imgs, 16, 28, 28)\r\n",
    "# after first MaxPool2d layer = (num_imgs, 16, 14, 14)\r\n",
    "# after second Conv2d = (num_imgs, 32, 14, 14)\r\n",
    "# after second MaxPool2d layer = (num_imgs, 32, 7, 7)\r\n",
    "# after flatten = (num_imgs, 32*7*7)\r\n",
    "# i.e. input of first dense layer should be 32*7*7\r\n",
    "\r\n",
    "class basicModel(nn.Module):\r\n",
    "    def __init__(self, num_classes):\r\n",
    "        super(basicModel, self).__init__()\r\n",
    "\r\n",
    "        self.conv_layers = nn.Sequential(\r\n",
    "            nn.Conv2d(1, 16, 5, 1, 1),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(2),\r\n",
    "            nn.Conv2d(16, 32, 5, 1, 1),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(2),\r\n",
    "            nn.Dropout2d(0.2),\r\n",
    "            nn.Flatten()\r\n",
    "        )\r\n",
    "\r\n",
    "        self.lin_layers = nn.Sequential(\r\n",
    "            nn.Linear(32*7*7, 128),\r\n",
    "            nn.Linear(128, 64),\r\n",
    "            nn.Linear(64, num_classes),\r\n",
    "        )\r\n",
    "\r\n",
    "        # self.softmax = nn.LogSoftmax(num_classes)\r\n",
    "    @profile\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.conv_layers(x)\r\n",
    "        x = self.lin_layers(x)\r\n",
    "        # x = self.softmax(x)\r\n",
    "\r\n",
    "        return x\r\n",
    "\r\n",
    "num_classes = len(np.unique(labels))\r\n",
    "model = basicModel(num_classes)\r\n",
    "loss_funk = nn.CrossEntropyLoss() \r\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# To Fix\r\n",
    "\r\n",
    "train model in batches to avoid running out of memory!!!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "num_epoch\r\n",
    "train_losses = []\r\n",
    "val_losses = []\r\n",
    "\r\n",
    "@profile\r\n",
    "def train(epoch):\r\n",
    "    model.train()\r\n",
    "    tr_loss = 0\r\n",
    "    data_train, label_train = Variable(train_data), Variable(train_label)\r\n",
    "    data_val, label_val = Variable(val_data), Variable(val_label)\r\n",
    "    \r\n",
    "    optimizer.zero_grad()\r\n",
    "    \r\n",
    "    output_train = model(train_data)\r\n",
    "    output_val = model(val_data)\r\n",
    "    \r\n",
    "    loss_train = loss_funk(output_train, train_label)\r\n",
    "    loss_val = loss_funk(output_val, val_label)\r\n",
    "    train_losses.append(loss_train)\r\n",
    "    val_losses.append(loss_val)\r\n",
    "    \r\n",
    "    loss_train.backward()\r\n",
    "    optimizer.step()\r\n",
    "    tr_loss = loss_train.item()\r\n",
    "    \r\n",
    "\r\n",
    "    # computing the updated weights of all the model parameters\r\n",
    "    loss_train.backward()\r\n",
    "    optimizer.step()\r\n",
    "    tr_loss = loss_train.item()\r\n",
    "    \r\n",
    "    print('\\n=====================================')\r\n",
    "    print(f'Epoch: {epoch+1}\\t loss: {loss_val}')\r\n",
    "    print('=====================================')\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "dba8851dec06c95965c4b9acd8f4325acdb80444c005ae414d7a6bcd36173821"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}